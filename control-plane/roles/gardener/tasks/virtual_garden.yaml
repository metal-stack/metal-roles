---
- name: Clone Gardener etcd (with backup restore)
  git:
    repo: "{{ gardener_etcd_repo_url }}"
    dest: "{{ gardener_local_tmp_dir }}/etcd-backup-restore"
    depth: 1
    version: "{{ gardener_etcd_repo_ref }}"

- name: Deploy Gardener etcd (with backup restore)
  include_role:
    name: ansible-common/roles/helm-chart
  vars:
    helm_timeout: "600s"
    helm_chart: "{{ gardener_local_tmp_dir }}/etcd-backup-restore/chart/etcd-backup-restore"
    helm_release_name: etcd-{{ metal_control_plane_stage_name }}
    helm_target_namespace: garden
    helm_value_file_template: etcd-values.j2

# The virtual garden setup requires one service through which the soil and the garden-apiserver can communicate
# This needs to have the same, static ip address, which needs to be chosen randomly from the service network
- name: Determine current gardener-apiserver service cluster ip
  set_fact:
    _gardener_api_server_current_service_ip: "{{ (lookup('k8s', api_version='v1', kind='Service', namespace='garden', resource_name='gardener-apiserver') | default({}, true)).get('spec', {}).get('clusterIP', none) }}"

- name: Calculate gardener-kube-apiserver service cluster IP
  set_fact:
    gardener_virtual_api_server_svc_cluster_ip: "{{ _gardener_api_server_current_service_ip if _gardener_api_server_current_service_ip else _gardener_soil_service_cidr | network_cidr_add(add=gardener_virtual_api_server_svc_cluster_ip_add) }}"

- name: Deploy kube-apiserver for virtual garden
  include_role:
    name: ansible-common/roles/helm-chart
  vars:
    helm_timeout: "600s"
    helm_chart_custom_folder: "{{ ansible_parent_role_paths[0] }}/files/kube-apiserver"
    helm_chart: "./kube-apiserver"
    helm_release_name: virtual-garden
    helm_target_namespace: garden
    helm_value_file_template: kube-apiserver-values.j2
    helm_chart_inject_config_hash: yes

- name: Read admin kubeconfig for garden-kube-apiserver
  copy:
    dest: "{{ gardener_kube_apiserver_kubeconfig_path }}"
    content: "{{ lookup('k8s', api_version='v1', kind='Secret', namespace='garden', resource_name='garden-kubeconfig-for-admin').get('data', {}).get('kubeconfig') | b64decode }}"

- name: Wait for garden-kube-apiserver
  wait_for:
    host: "{{ gardener_virtual_api_server_public_dns }}"
    port: "{{ gardener_virtual_api_server_public_port }}"
    timeout: 60

# the admin kubeconfig is in the seeds group that gets created by the gardenlet.
# to make it available earlier, let's create it with a custom admin cert
#
# we should move to the Gardener Operator soon to get rid off these hacks!

- name: Create private key to setup virtual garden admin
  community.crypto.openssl_privatekey:
    path: "{{ gardener_local_tmp_dir }}/system-masters-kubeconfig-key"
    type: ECC
    size: 256
    curve: secp256r1

- name: Create certificate signing request
  community.crypto.openssl_csr_pipe:
    privatekey_path: "{{ gardener_local_tmp_dir }}/system-masters-kubeconfig-key"
    common_name: admin
    organization_name: system:masters
    key_usage:
      - digitalSignature
      - keyEncipherment
    extended_key_usage:
      - serverAuth
      - clientAuth
  register: result

- name: Create certificate
  community.crypto.x509_certificate:
    csr_content: "{{ result.csr }}"
    path: "{{ gardener_local_tmp_dir }}/system-masters-kubeconfig-cert"
    privatekey_path: "{{ gardener_local_tmp_dir }}/system-masters-kubeconfig-key"
    ownca_content: "{{ gardener_kube_api_server_ca }}"
    ownca_privatekey_content: "{{ gardener_kube_api_server_ca_key }}"
    provider: ownca
    return_content: true
  register: result

- name: Write the kubeconfig
  copy:
    dest: "{{ gardener_local_tmp_dir }}/system-masters-kubeconfig"
    content: "{{ (gardener_virtual_api_server_public_dns + ':' + (gardener_virtual_api_server_public_port | string)) | kubeconfig_from_cert(gardener_kube_api_server_ca, result.certificate, lookup('file', gardener_local_tmp_dir + '/system-masters-kubeconfig-key'), prepend_https=true) }}"

- name: Create gardener seeds cluster role
  k8s:
    kubeconfig: "{{ gardener_local_tmp_dir }}/system-masters-kubeconfig"
    apply: true
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRole
      metadata:
        name: gardener.cloud:system:seeds
        annotations:
          meta.helm.sh/release-name: controlplane
          meta.helm.sh/release-namespace: garden
        labels:
          app.kubernetes.io/managed-by: Helm
      rules:
      - apiGroups:
        - '*'
        resources:
        - '*'
        verbs:
        - '*'

- name: Create gardener seeds cluster role binding
  k8s:
    kubeconfig: "{{ gardener_local_tmp_dir }}/system-masters-kubeconfig"
    apply: true
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: gardener.cloud:system:seeds
        annotations:
          meta.helm.sh/release-name: controlplane
          meta.helm.sh/release-namespace: garden
        labels:
          app.kubernetes.io/managed-by: Helm
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: gardener.cloud:system:seeds
      subjects:
      - apiGroup: rbac.authorization.k8s.io
        kind: Group
        name: gardener.cloud:system:seeds

- name: Cleanup these certificates again
  file:
    path: "{{ item }}"
    state: absent
  loop:
    - "{{ gardener_local_tmp_dir }}/system-masters-kubeconfig"
    - "{{ gardener_local_tmp_dir }}/system-masters-kubeconfig-cert"
    - "{{ gardener_local_tmp_dir }}/system-masters-kubeconfig-key"
